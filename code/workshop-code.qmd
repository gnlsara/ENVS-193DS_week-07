---
title: "ENVS 193DS week 7 coding workshop"
format: html
execute: 
  warning: false
  message: false
---

no warnings: message = false, eval = false

# Set-up

```{r libraries}
library(tidyverse)
library(here)
library(lterdatasampler)
# would be nice to have
library(performance) 
library(broom) 
library(flextable) # create tables that will render nicely
library(ggeffects) # get predictions from models
library(car) # pull out anova tables specifically for linear model
library(naniar)
```

# Linear Models

How does stem length predict stem dry mass?

```{r filtering-data}
maples_data <- hbr_maples %>% 
  filter(year==2003 & watershed=="Reference")
# and symbol makes more sense logically
```

Visualizing missing data

```{r missing-data-vis}
gg_miss_var(maples_data)
```

Create an exploratory data visualization

```{r explore-data-vis}
ggplot(data = maples_data, aes(x=stem_length, y=stem_dry_mass)) +
  geom_point()
```

Let's try a model

```{r linear-model-maples}
maples_model <- lm(stem_dry_mass ~ stem_length, data = maples_data)
maples_model # y intercept and slope for stem length
```

Check assumptions

1.  linear relationship between variables: yes (exploratory data visualization)
2.  independence of errors for residuals: yes (because they're taken all in one year in one watershed - based on how data was collected)
3.  homoskedasticity of errors: yes (residual vs. fitted plot / scale location plot)
4.  normally distributed errors or residuals: yes (looking at qq plot of residuals)

```{r checking-assumptions}
# use plot(maples_model) in the console to test for plots (see lecture 7)
  # homoscedastic, normally distributed (follows linear path), not really any influential outliers
# to display all four at once:
par(mfrow = c(2,2)) # set up 2 x 2 grid
plot(maples_model)
```

turn off 2 x 2 grid

```{r turn-off-grid, results = FALSE}
dev.off()
```

# putting things together to communicate

## model predictions

```{r pulling-out-predictions}
predictions <- ggpredict(maples_model, terms = "stem_length")
View(predictions) # terms corresponds to whatever predictor was in model
```

plot predictions

```{r plotting-predictions}
plot_predictions <- ggplot(data = maples_data, aes(x = stem_length, y = stem_dry_mass))+
  geom_point() + # first plot underlying data
  # plotting model predictions from predictions object from ggeffects
  geom_line(data = predictions, aes(x = x, y = predicted), color = "blue", linewidth = 1) +
  geom_ribbon(data = predictions, aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high), alpha = 0.2)
plot_predictions

# plot of model that tells you nothing
ggplot(data = maples_data, aes(x = stem_length, y = stem_dry_mass))+
  geom_point() +
  geom_smooth(method = "lm")
```

## create a table

```{r model_summary_table}
maples_model
summary(maples_model)
model_summary <- summary(maples_model)
model_squares <- anova(maples_model)
model_squares
```

making a table

```{r}
model_squares_table <- tidy(model_squares) %>% 
  mutate(p.value = case_when(
    p.value < 0.001 ~ "< 0.001"
  )) %>% 
  flextable() %>% 
  set_header_labels(df = "Degrees of Freedom", sumsq = "Sum of Squares", meansq = "Mean of Squares")
model_squares_table
```
